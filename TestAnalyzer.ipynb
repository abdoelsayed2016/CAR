{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, codecs\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(20,20))\n",
    "ax1.text(2000, 80, \"TEST2 (NomeroffNet Model)\", fontsize=24)\n",
    "ax1.text(2000, 40, \"Average precision: \" + str(avg_acc) + \"%\", fontsize=24)\n",
    "width = 0.7\n",
    "plt.rcParams['font.size'] = 12\n",
    "ax1.xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=.5)\n",
    "ax1.set_xticks(np.linspace(0, 5000, 21))\n",
    "ax1.set_xlabel('Number of characters', fontsize = 20)\n",
    "ax1.set_ylabel('Characters', fontsize = 20)\n",
    "rects = ax1.barh(list(sorted_freq_symbols.keys()), sorted_freq_symbols_freq, width, color = 'k', log = False, label='number of annotation characters')\n",
    "rects_acc = ax1.barh(list(sorted_freq_symbols.keys()), sorted_freq_symbols_pred, width, color = 'gray', log = False, label='number of predicted characters')\n",
    "ax1.legend(loc=\"lower right\", fontsize = 20)\n",
    "for i, rect in enumerate(rects):\n",
    "    yloc = rect.get_y() + rect.get_height() / 2\n",
    "    xloc = -5\n",
    "    width = int(rect.get_width())\n",
    "    # The bars aren't wide enough to print the ranking inside\n",
    "    if width < 999999:\n",
    "        # Shift the text to the right side of the right edge\n",
    "        xloc = 2\n",
    "        # Black against white background\n",
    "        clr = 'black'\n",
    "        align = 'left'\n",
    "    else:\n",
    "        # Shift the text to the left side of the right edge\n",
    "        xloc = -5\n",
    "        # White on magenta\n",
    "        clr = 'white'\n",
    "        align = 'right'\n",
    "    label = ax1.annotate(str(sorted_freq_symbols_acc[i])+'%', xy=(width, yloc), xytext=(xloc, 0),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha=align, va='center',\n",
    "                            color=clr, clip_on=True, fontsize=12)\n",
    "#plt.show()\n",
    "plt.savefig('C:/Users/lenovo/Documents/Projects/kazpost/test/Nomeroff_test2_symbols_black.png', size=6, transparent=False, bbox_inches='tight', pad_inches=0, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbols_calc(all_files): \n",
    "    symbols = {}\n",
    "    words = {}\n",
    "    for file_id, filename in enumerate(all_files):\n",
    "        #if file_id < 149:\n",
    "        #    continue\n",
    "        with codecs.open(filename,'r', encoding=\"utf-8\") as df:\n",
    "            data = json.load(df)\n",
    "            description = data['description']\n",
    "            predicted = data['moderation']['predicted']\n",
    "            predicted_copy = predicted\n",
    "        #print(file_id, filename, description, '-', predicted)\n",
    "        j = 0\n",
    "        k = 0\n",
    "        correct_chars_sum = 0\n",
    "        for i, ch in enumerate(description):\n",
    "            if not ch in symbols:\n",
    "                symbols[ch] = {'freq': 1, 'pred': 0, 'acc': 0}\n",
    "            else:\n",
    "                symbols[ch]['freq'] += 1\n",
    "            try:\n",
    "                if ch == predicted[j]:\n",
    "                    symbols[ch]['pred'] += 1\n",
    "                    correct_chars_sum += 1\n",
    "                    predicted_copy = predicted_copy[:j-k] + predicted_copy[j-k+1:]\n",
    "                    k += 1\n",
    "                    j += 1\n",
    "                else:\n",
    "                    if ch == predicted[j+1]:\n",
    "                        symbols[ch]['pred'] += 1\n",
    "                        correct_chars_sum += 1\n",
    "                        predicted_copy = predicted_copy[:j-k+1] + predicted_copy[j-k+2:]\n",
    "                        k += 1\n",
    "                        j += 2\n",
    "                    elif ch == predicted[j+2]:\n",
    "                        symbols[ch]['pred'] += 1\n",
    "                        correct_chars_sum += 1\n",
    "                        predicted_copy = predicted_copy[:j-k+2] + predicted_copy[j-k+3:]\n",
    "                        k += 1\n",
    "                        j += 3\n",
    "                    else:\n",
    "                        #print(ch)\n",
    "                        pass\n",
    "            except:\n",
    "                #print(\"Out of index\")\n",
    "                pass\n",
    "\n",
    "        for ex_ch in predicted_copy:\n",
    "            if not ex_ch in symbols:\n",
    "                symbols[ex_ch] = {'freq': 1, 'pred': 0, 'acc': 0}\n",
    "            else:\n",
    "                symbols[ex_ch]['freq'] += 1\n",
    "\n",
    "        words[filename] = {'desc': description, 'pred': predicted, \n",
    "                       'Lev': fuzz.ratio(description, predicted),\n",
    "                       'Our': round((correct_chars_sum/(len(description) + len(predicted_copy)))*100),\n",
    "                       'delta': abs(fuzz.ratio(description, predicted) - round((correct_chars_sum/(len(description) + len(predicted_copy)))*100))}\n",
    "        #if file_id > 40:\n",
    "        #    break\n",
    "    l = 0\n",
    "    for key, val in symbols.items():\n",
    "        val['acc'] = round((val['pred']/val['freq'])*100)\n",
    "        l += val['freq']\n",
    "    \n",
    "    symbols = OrderedDict(sorted(symbols.items(), key = lambda x : x[1]['freq'], reverse=False))\n",
    "    return symbols, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbols_calc_Rasul(all_files): \n",
    "    symbols = {}\n",
    "    words = {}\n",
    "    for file_id, filename in enumerate(all_files):\n",
    "        #if file_id < 149:\n",
    "        #    continue\n",
    "        with codecs.open(filename,'r', encoding=\"utf-8\") as df:\n",
    "            data = json.load(df)\n",
    "            description = data['description']\n",
    "            predicted = data['moderation']['predicted']\n",
    "        #print(file_id, filename, description, '-', predicted)\n",
    "\n",
    "        for ch in description:\n",
    "            if not ch in symbols:\n",
    "                symbols[ch] = {'freq': 1, 'pred': 0, 'acc': 0}\n",
    "            else:\n",
    "                symbols[ch]['freq'] += 1\n",
    "        correct_chars = []\n",
    "        correct_chars_sum = 0\n",
    "        for outerindex in range(len(description)):\n",
    "            try:\n",
    "                match_cnt = 0\n",
    "                for i1 in range(outerindex, len(description)):\n",
    "                    ind2 = max(0, i1-2)\n",
    "                    ind2plus3 = ind2 + 4\n",
    "                    while ind2 < min(ind2plus3, len(predicted)):\n",
    "                        if (description[i1] == predicted[ind2]):\n",
    "                            match_cnt += 1\n",
    "                            ind2 += 1\n",
    "                            ind2plus3 = ind2 + 4\n",
    "                            if match_cnt > correct_chars_sum:\n",
    "                                correct_chars_sum = match_cnt\n",
    "                                #print(description[i1], correct_chars_sum)\n",
    "                                symbols[description[i1]]['pred'] += 1\n",
    "                                correct_chars.append(description[i1])\n",
    "                            break\n",
    "                        else:\n",
    "                            ind2 += 1\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                pass\n",
    "\n",
    "        incorrect_predicted_chars = []                                                         \n",
    "        for p_ch in predicted:\n",
    "            if not p_ch in correct_chars:\n",
    "                incorrect_predicted_chars.append(p_ch)\n",
    "                                                                 \n",
    "        for ex_ch in incorrect_predicted_chars:\n",
    "            if not ex_ch in symbols:\n",
    "                symbols[ex_ch] = {'freq': 1, 'pred': 0, 'acc': 0}\n",
    "            else:\n",
    "                symbols[ex_ch]['freq'] += 1\n",
    "            \n",
    "        words[filename] = {'desc': description, 'pred': predicted, \n",
    "                       'Lev': fuzz.ratio(description, predicted),\n",
    "                       'Our': round((correct_chars_sum/(len(description) + len(incorrect_predicted_chars)))*100),\n",
    "                       'delta': abs(fuzz.ratio(description, predicted) - round((correct_chars_sum/(len(description) + len(incorrect_predicted_chars)))*100))}\n",
    "        #if file_id > 40:\n",
    "        #    break\n",
    "    l = 0\n",
    "    for key, val in symbols.items():\n",
    "        val['acc'] = round((val['pred']/val['freq'])*100)\n",
    "        l += val['freq']\n",
    "    \n",
    "    symbols = OrderedDict(sorted(symbols.items(), key = lambda x : x[1]['freq'], reverse=False))\n",
    "    return symbols, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Word accuracy rate\n",
    "def words_calc(all_files, model_name):   \n",
    "    correct_words = 0\n",
    "    car_sum = 0\n",
    "    for file_id, filename in enumerate(all_files):\n",
    "        with codecs.open(filename,'r', encoding=\"utf-8\") as df:\n",
    "            data = json.load(df)\n",
    "            description = data['description']\n",
    "            predicted = data['moderation']['predicted']\n",
    "        # equal words\n",
    "        if description == predicted:\n",
    "            correct_words +=1\n",
    "        # Levenshtein distance\n",
    "        car_sum += fuzz.ratio(description, predicted)\n",
    "    print(model_name + \" WAR:\" , round(correct_words/len(all_files) * 10000)/100, \"%\")\n",
    "    print(model_name + \" CAR: \", round(car_sum/len(all_files) * 100)/100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Flor Model (modified)'\n",
    "TEST1_DIR = model_name + \"/test1/ann_pred\"\n",
    "TEST2_DIR = model_name + \"/test2/ann_pred\"\n",
    "\n",
    "#test1_symbols, test1_words = symbols_calc(glob.glob(os.path.join(TEST1_DIR,\"*.json\")))\n",
    "#test2_symbols, test2_words = symbols_calc(glob.glob(os.path.join(TEST2_DIR,\"*.json\")))\n",
    "#words_calc(glob.glob(os.path.join(TEST1_DIR,\"*.json\")), model_name)\n",
    "test1_symbols, test1_words = symbols_calc_Rasul(glob.glob(os.path.join(TEST1_DIR,\"*.json\")))\n",
    "test2_symbols, test2_words = symbols_calc_Rasul(glob.glob(os.path.join(TEST2_DIR,\"*.json\")))\n",
    "words_calc(glob.glob(os.path.join(TEST1_DIR,\"*.json\")), model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_name)\n",
    "sorted_words = OrderedDict(sorted(test1_words.items(), key = lambda x : x[1]['delta'], reverse=True))\n",
    "i = 0\n",
    "for name, value in sorted_words.items():\n",
    "    print(value)\n",
    "    i += 1\n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1_symbols_freq = [x['freq'] for x in test1_symbols.values()]\n",
    "test1_symbols_pred = [x['pred'] for x in test1_symbols.values()]\n",
    "test1_symbols_acc = [x['acc'] for x in test1_symbols.values()]\n",
    "test1_avg_acc = round(sum(test1_symbols_acc)/len(test1_symbols_acc)*100)/100\n",
    "print(test1_avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2_symbols_freq = [x['freq'] for x in test2_symbols.values()]\n",
    "test2_symbols_pred = [x['pred'] for x in test2_symbols.values()]\n",
    "test2_symbols_acc = [x['acc'] for x in test2_symbols.values()]\n",
    "test2_avg_acc = round(sum(test2_symbols_acc)/len(test2_symbols_acc)*100)/100\n",
    "print(test2_avg_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(25,20), sharey=False)\n",
    "ax1.text(2750, 85, \"Character Accuracy Rates (CAR), \" + model_name, fontsize=24)\n",
    "\n",
    "#AX1 axis\n",
    "ax1.text(2000, 80, \"on TEST1\", fontsize=24)\n",
    "ax1.text(2000, 40, \"Average CAR: \" + str(test1_avg_acc) + \"%\", fontsize=24)\n",
    "width = 0.7\n",
    "plt.rcParams['font.size'] = 12\n",
    "ax1.xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=.5)\n",
    "ax1.set_xticks(np.linspace(0, 5500, 5))\n",
    "ax1.set_xlabel('Number of characters', fontsize = 20)\n",
    "ax1.set_ylabel('Characters', fontsize = 20)\n",
    "rects = ax1.barh(list(test1_symbols.keys()), test1_symbols_freq, width, color = 'r', log = False, label='number of annotation characters')\n",
    "rects_acc = ax1.barh(list(test1_symbols.keys()), test1_symbols_pred, width, color = 'g', log = False, label='number of predicted characters')\n",
    "ax1.legend(loc=\"lower right\", fontsize = 20)\n",
    "for i, rect in enumerate(rects):\n",
    "    yloc = rect.get_y() + rect.get_height() / 2\n",
    "    xloc = -5\n",
    "    width = int(rect.get_width())\n",
    "    # The bars aren't wide enough to print the ranking inside\n",
    "    if width < 999999:\n",
    "        # Shift the text to the right side of the right edge\n",
    "        xloc = 2\n",
    "        # Black against white background\n",
    "        clr = 'black'\n",
    "        align = 'left'\n",
    "    else:\n",
    "        # Shift the text to the left side of the right edge\n",
    "        xloc = -5\n",
    "        # White on magenta\n",
    "        clr = 'white'\n",
    "        align = 'right'\n",
    "    label = ax1.annotate(str(test1_symbols_acc[i])+'%', xy=(width, yloc), xytext=(xloc, 0),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha=align, va='center',\n",
    "                            color=clr, clip_on=True, fontsize=12)\n",
    "    for i in range(len(test1_symbols_freq)):\n",
    "        if list(test1_symbols.keys())[i] in ['а','я', 'А', 'Ж','щ','э','Қ','ғ']:\n",
    "            ax1.text(-550 , i-0.25, str(list(test1_symbols.keys())[i]), color='black', fontsize='24')\n",
    "  \n",
    "\n",
    "# AX2 axis\n",
    "ax2.text(2000, 80, \"on TEST2\", fontsize=24)\n",
    "ax2.text(2000, 40, \"Average CAR: \" + str(test2_avg_acc) + \"%\", fontsize=24)\n",
    "width = 0.7\n",
    "plt.rcParams['font.size'] = 13\n",
    "ax2.xaxis.grid(True, linestyle='--', which='major', color='grey', alpha=.5)\n",
    "ax2.set_xticks(np.linspace(0, 5500, 5))\n",
    "ax2.set_xlabel('Number of characters', fontsize = 20)\n",
    "ax2.set_ylabel('Characters', fontsize = 20)\n",
    "rects = ax2.barh(list(test2_symbols.keys()), test2_symbols_freq, width, color = 'r', log = False, label='number of annotation characters')\n",
    "rects_acc = ax2.barh(list(test2_symbols.keys()), test2_symbols_pred, width, color = 'g', log = False, label='number of predicted characters')\n",
    "ax2.legend(loc=\"lower right\", fontsize = 20)\n",
    "for i, rect in enumerate(rects):\n",
    "    yloc = rect.get_y() + rect.get_height() / 2\n",
    "    xloc = -5\n",
    "    width = int(rect.get_width())\n",
    "    # The bars aren't wide enough to print the ranking inside\n",
    "    if width < 999999:\n",
    "        # Shift the text to the right side of the right edge\n",
    "        xloc = 2\n",
    "        # Black against white background\n",
    "        clr = 'black'\n",
    "        align = 'left'\n",
    "    else:\n",
    "        # Shift the text to the left side of the right edge\n",
    "        xloc = -5\n",
    "        # White on magenta\n",
    "        clr = 'white'\n",
    "        align = 'right'\n",
    "    label = ax2.annotate(str(test2_symbols_acc[i])+'%', xy=(width, yloc), xytext=(xloc, 0),\n",
    "                            textcoords=\"offset points\",\n",
    "                            ha=align, va='center',\n",
    "                            color=clr, clip_on=True, fontsize=12)\n",
    "    for i in range(len(test2_symbols_freq)):\n",
    "        if list(test2_symbols.keys())[i] in ['а','я', 'А', 'Ж','щ','э','Қ','ғ']:\n",
    "            ax2.text(-700 , i, str(list(test2_symbols.keys())[i]), color='black', fontsize='24')\n",
    "    \n",
    "#plt.show()\n",
    "plt.savefig('CAR2_'+model_name+'.png', size=6, transparent=False, bbox_inches='tight', pad_inches=0, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
